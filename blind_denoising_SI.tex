\documentclass{article}

% Recommended, but optional, packages for figures and better typesetting:
\usepackage{microtype}
\usepackage{graphicx}
\usepackage{subfigure}
\usepackage{booktabs} % for professional tables

% hyperref makes hyperlinks in the resulting PDF.
% If your build breaks (sometimes temporarily if a hyperlink spans a page)
% please comment out the following usepackage line and replace
% \usepackage{icml2021} with \usepackage[nohyperref]{icml2021} above.
\usepackage{hyperref}

% Attempt to make hyperref and algorithmic work together better:
\newcommand{\theHalgorithm}{\arabic{algorithm}}

% Use the following line for the initial blind version submitted for review:
\usepackage{icml2021}

% custom packages
\usepackage{amsmath}
\usepackage{amssymb}
% for referencing footnotes several times. to load after hyperref
\usepackage{cleveref}
\crefformat{footnote}{#2\footnotemark[#1]#3}
% \usepackage{times}
% \usepackage{epsfig}
% If accepted, instead use the following line for the camera-ready submission:
%\usepackage[accepted]{icml2021}

% The \icmltitle you define below is probably too long as a header.
% Therefore, a short form for the running title is supplied here:
\icmltitlerunning{SI for Joint self-supervised blind denoising and noise estimation}
\renewcommand{\thetable}{S\arabic{table}}
\renewcommand{\thefigure}{S\arabic{figure}}
\renewcommand{\thesection}{S\arabic{section}}
% \newcommand{\beginsupplement}{
%  }

\begin{document}
\twocolumn[
\icmltitle{Supplementary information for Joint self-supervised blind denoising and noise estimation}

\icmlsetsymbol{equal}{*}

\begin{icmlauthorlist}
\icmlauthor{Jean Ollion}{sabilab}
\icmlauthor{Charles Ollion}{cmap}
\icmlauthor{\'Elisabeth Gassiat}{ups}
\icmlauthor{Sylvain Le Corff}{tsp,cmap}
\icmlauthor{Luc Leh\'ericy}{uca}
\end{icmlauthorlist}

\icmlaffiliation{sabilab}{SABILab, Die, France}
\icmlaffiliation{cmap}{CMAP, Ecole Polytechnique, Institut Polytechnique de Paris, France}
\icmlaffiliation{tsp}{Samovar, T\'el\'ecom SudParis, D\'epartement CITI, Institut Polyechnique de Paris, France}
\icmlaffiliation{ups}{Universit\'e Paris-Saclay, CNRS, Laboratoire de math\'ematiques d'Orsay, 91405, Orsay, France}
\icmlaffiliation{uca}{Laboratoire J. A. Dieudonn\'e, Universit\'e C\^ote d'Azur, CNRS, 06108, Nice, France}

\icmlcorrespondingauthor{Jean Ollion}{jean.ollion@polytechnique.org}
\icmlcorrespondingauthor{Sylvain Le Corff}{sylvain.le_corff@telecom-sudparis.eu}

\icmlkeywords{Blind Denoising, Self-supervised, Bio-image, Machine Learning}

\vskip 0.3in


\section{Additional Implementation details}
\label{si:implementation}
\paragraph{Networks and training.}
We propose several changes from the original version: we do not crop the image and use zero-padding instead, we use 2 levels of contractions/expansions with 64 filters, expansions is performed by an upsampling layer with nearest-neighbor approximation directly followed by 2x2 convolution, we added two layers of 1x1 convolution with 64 filters and ReLU activation at the end of the network, and set no activation function at the output layer.
The receptive field of this network is 35x35 pixels, which means that the network may use pixels from the neighorhood that are masked.

\paragraph{N-Net architecture details}
In the case of Gaussian output, the N-Net is composed 3 successive blocks, each block being composed of two 1x1 convolutions layers of 64 filters, each followed by a non-linear activation layer (alternatively tanh and leaky ReLU with alpha parameter set to $0.1$). A convolution 1x1 with a single channel followed by an exponential activation function is placed after the last block (to ensure the predicted $\sigma$ is positive).

In the case N-net predicts a GMM with N components, the second block is connected to three distinct blocks, each connected to a convolution 1x1 with:
\begin{itemize}
  \item N channels, followed by an exponential activation function to predict $\sigma_{i}$
  \item N channels, followed by a softmax activation to predict $\alpha_{i}$\footnote{In case $N=2$ only one channel is predicted followed by a sigmoid activation function}
  \item N-1 channels to predict the ditribution centers $\mu_{i}$.
\end{itemize}
To ensure that the distribution is centered, the center of the last distribution is computed as $\mu_{N} = \frac{1}{\alpha_{N-1}} * \sum_{i=1}^{N-1}{\alpha_{i} * \mu{i}}$

\section{Datasets}
\subsection{Experimental Datasets}
\label{si:datasetxp}
\paragraph{Datasets published along with the PN2V \cite{krull2019probabilistic}.}
\begin{itemize}
  \item \emph{Convallaria} dataset, referred to as \emph{PN2V-C} is composed of 100 images of size $1024$x$1024$, validation subset is:
  \item \emph{Mouse skull nuclei} referred to as \emph{PN2V-MN} is composed 200 images of size $512$x$512$, validation subset is:
  \item \emph{Mouse Actin} referred to as \emph{PN2V-MA} is composed of 100 images of size $1024$x$1024$, validation subset is:
\end{itemize}
Evaluation subsets:
% \emph{PN2V-C} : ($[0, 512]$, $[0, 512]$)
% \emph{PN2V-MN} : $([0, 512], [0, 256])$
% \emph{PN2V-MA} : $([0, 1024], [0, 512])$
\textcolor{red}{TODO FIX EVALUATION SUBBSETS}
\textcolor{red}{TODO provide links}

\paragraph{Datasets published in \cite{zhou2020w2s}.}
We used the 16-bit raw images kindly provided by the authors.
The dataset is composed of 120 FOV of 400 observations of size $512$x$512$ pixels.
The first 80 are used for training and the last 40 for evaluation.
Following the authors, for each FOV, only the observation of index 249 is used for training and evaluation

For both datasets images were normalized using the modal value as center and the difference between modal value and $95\%$ percentile as scale factor, computed on the whole dataset.
This is relevant in fluorescence microscopy data where signal is often less abundant than background with proportion that vary among images and signal distribution has often an heavy tail towards high values.

For the 6 chosen datasets, images are encoded in 16-bit thus the actual data range of each ground truth image is used for PSNR and SSIM computation.

\subsection{Synthetic noise datasets}
\label{si:synthetic}
\begin{itemize}
  \item Additive gaussian: $y = x + N(0, \sigma)$ with $\sigma=20$
  \item Poisson-Gaussian: $y = x + \sqrt{\alpha * (x-min(x)) + \eta^2 }*N(0,1)$ with $\alpha=5, \eta=12$ and $min(x)$ begin the minimal value of the ground truth on the whole dataset.
  \item Speckle: $y = x + (x-min(x))*N(0,\sigma)$ with $\sigma=0.405$
\end{itemize}

{\small
\bibliography{blind_denoising}
\bibliographystyle{icml2021}
}
] % end of 1-column area
\end{document}
